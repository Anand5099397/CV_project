# -*- coding: utf-8 -*-
"""CV_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10rbepQkUsK3ux6OTQ47rZqzTXK0FSG09
"""

!pip install torchvision pytorch-msssim

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
from pytorch_msssim import ssim

# =====================
# 1. Synthetic Dataset
# =====================
class SyntheticDepthDataset(Dataset):
    def __init__(self, size=1000, img_size=(256, 256)):
        self.img_size = img_size
        self.size = size

    def __len__(self):
        return self.size

    def __getitem__(self, idx):
        # Generate random RGB image (noise + gradient)
        rgb = torch.rand(3, *self.img_size)  # Random noise [0,1]

        # Generate depth map (vertical gradient + random shape)
        depth = torch.zeros(1, *self.img_size)
        y = torch.arange(self.img_size[0]).float() / self.img_size[0]
        depth[0] = y.view(-1, 1)  # Vertical gradient

        # Add random rectangle
        cx, cy = np.random.randint(0, self.img_size[1]), np.random.randint(0, self.img_size[0])
        w, h = np.random.randint(30, 100), np.random.randint(30, 100)
        depth[0, cy:cy+h, cx:cx+w] = 1.0  # Rectangle with max depth

        return rgb, depth

# =====================
# 2. U-Net Architecture
# =====================
class DepthUNet(nn.Module):
    def __init__(self):
        super().__init__()

        # Encoder
        self.enc1 = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU())
        self.pool1 = nn.MaxPool2d(2)
        self.enc2 = nn.Sequential(nn.Conv2d(64, 128, 3, padding=1), nn.ReLU())
        self.pool2 = nn.MaxPool2d(2)

        # Bottleneck
        self.bottleneck = nn.Sequential(nn.Conv2d(128, 256, 3, padding=1), nn.ReLU())

        # Decoder with skip connections
        self.up1 = nn.Upsample(scale_factor=2)
        self.dec1 = nn.Sequential(nn.Conv2d(256+128, 128, 3, padding=1), nn.ReLU())
        self.up2 = nn.Upsample(scale_factor=2)
        self.dec2 = nn.Sequential(nn.Conv2d(128+64, 64, 3, padding=1), nn.ReLU())

        # Final output
        self.final = nn.Conv2d(64, 1, 1)

    def forward(self, x):
        # Encoder
        e1 = self.enc1(x)      # [B,64,H,W]
        x = self.pool1(e1)     # [B,64,H/2,W/2]
        e2 = self.enc2(x)      # [B,128,H/2,W/2]
        x = self.pool2(e2)     # [B,128,H/4,W/4]

        # Bottleneck
        x = self.bottleneck(x) # [B,256,H/4,W/4]

        # Decoder
        x = self.up1(x)        # [B,256,H/2,W/2]
        x = torch.cat([x, e2], dim=1)  # [B,256+128,H/2,W/2]
        x = self.dec1(x)       # [B,128,H/2,W/2]

        x = self.up2(x)        # [B,128,H,W]
        x = torch.cat([x, e1], dim=1)  # [B,128+64,H,W]
        x = self.dec2(x)       # [B,64,H,W]

        return self.final(x)   # [B,1,H,W]

# =====================
# 3. Training Setup
# =====================
def depth_loss(pred, target):
    l1_loss = F.l1_loss(pred, target)
    ssim_loss = 1 - ssim(pred, target, data_range=1.0, size_average=True)
    return l1_loss + 0.5 * ssim_loss

# Initialize components
dataset = SyntheticDepthDataset(size=1000, img_size=(256, 256))
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)
model = DepthUNet().cuda()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# =====================
# 4. Training Loop
# =====================
for epoch in range(25):
    model.train()
    epoch_loss = 0.0

    for rgb, depth in train_loader:
        rgb = rgb.cuda().float()
        depth = depth.cuda().float()

        # Forward pass
        pred = model(rgb)

        # Compute loss
        loss = depth_loss(pred, depth)

        # Backprop
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()

    print(f"Epoch {epoch+1}/25 | Loss: {epoch_loss/len(train_loader):.4f}")

# 5. Visualization

model.eval()
with torch.no_grad():
    rgb, depth = dataset[0]  # Get first sample
    pred = model(rgb.unsqueeze(0).cuda()).squeeze().cpu()

# Convert to numpy
rgb_np = rgb.permute(1, 2, 0).numpy()
depth_np = depth.squeeze().numpy()
pred_np = pred.numpy()

# Plot
plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.imshow(rgb_np)
plt.title("RGB Input")
plt.axis('off')

plt.subplot(1, 3, 2)
plt.imshow(depth_np, cmap='inferno', vmin=0, vmax=1)
plt.title("Ground Truth Depth")
plt.axis('off')

plt.subplot(1, 3, 3)
plt.imshow(pred_np, cmap='inferno', vmin=0, vmax=1)
plt.title("Predicted Depth")
plt.axis('off')

plt.show()